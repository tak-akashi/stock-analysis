---
description: コード品質・設計整合性検証
---

# コード品質検証

**目的:** 実装コードの品質を5つの観点から検証し、要件/設計との整合性を確認します。

**引数:**
- `/validate-code [パス]` - 指定したパス（ファイルまたはディレクトリ）を検証
- `/validate-code [.steeringパス]` - 指定したsteeringディレクトリの実装を検証
- `/validate-code` - 最新のsteeringディレクトリを自動検出して検証

---

## 検証観点

| # | 観点 | 内容 |
|---|------|------|
| 1 | スペック整合性 | 要件/設計との対応確認 |
| 2 | コード品質 | コーディング規約、ベストプラクティス |
| 3 | テストカバレッジ | テストの網羅性と品質 |
| 4 | セキュリティ | 脆弱性、機密情報の取り扱い |
| 5 | パフォーマンス | 効率性、リソース使用 |

---

## ステップ1: 検証対象の特定

1. **引数の解析**

   ```
   # パス指定時
   対象パス = 引数で指定されたパス

   # .steering指定時
   Read('[指定された.steeringパス]/tasklist.md')
   → 実装されたファイルリストを抽出

   # 引数なし時（最新を自動検出）
   Bash('ls -t .steering/ | head -1')
   → 最新のsteeringディレクトリを使用
   ```

2. **関連ファイルの収集**

   steeringディレクトリ内の全ファイルを収集:
   ```
   Glob('[steeringパス]/*.md')
   ```

   標準ファイル:
   - `requirements.md` - 受け入れ条件の参照
   - `design.md` - 設計との整合性確認
   - `tasklist.md` - 実装ファイルリストの抽出

   カスタムファイル（存在する場合）:
   - その他の`.md`ファイル - 追加の設計・計画ドキュメントとして参照

---

## ステップ2: スペックとの整合性検証

`Skill('validation')`の**スペック整合性モード**を使用。

### 2.1 要件の抽出

```
Read('[steeringパス]/requirements.md')
→ 「受け入れ条件」セクションから条件リストを抽出
```

### 2.2 設計の抽出

```
Read('[steeringパス]/design.md')
→ クラス設計、インターフェース、データフローを抽出
```

### 2.3 追加ドキュメントの参照（存在する場合）

```
# requirements.md, design.md, tasklist.md 以外のファイル
Glob('[steeringパス]/*.md')
→ 追加の計画・設計ドキュメントを参照
→ 実装の意図や詳細仕様の確認に使用
```

### 2.4 条件とコードの対応確認

各条件について:

```
# クラス/関数の存在確認
Grep('class {期待するクラス名}', 'src/')
Grep('def {期待する関数名}', 'src/')

# インターフェースの確認
Grep('{メソッドシグネチャ}', 'src/')
```

### 2.5 アーキテクチャとの整合性

```
Read('docs/core/architecture.md')
→ 既存パターンとの整合性確認
```

---

## ステップ3: コード品質検証

`Skill('validation')`の**コード品質モード**を使用。

### 3.1 ruff check

```bash
Bash('uv run ruff check [対象パス] --output-format=grouped')
```

**チェック項目:**
- pyflakes (F): 未使用import、未定義変数
- pycodestyle (E, W): PEP8スタイル違反
- isort (I): import順序
- flake8-bugbear (B): バグになりやすいパターン

### 3.2 mypy

```bash
Bash('uv run mypy [対象パス] --show-error-codes --no-error-summary')
```

**チェック項目:**
- 型の不一致
- 未定義の属性アクセス
- Optional型の未チェック使用

### 3.3 ベストプラクティス確認

- 適切なエラーハンドリング
- ログ出力の適切さ
- 関数/クラスの単一責任
- DRY原則への準拠

---

## ステップ4: テストカバレッジ検証

`Skill('validation')`の**テストカバレッジモード**を使用。

### 4.1 テストファイルの存在確認

```
Glob('tests/**/test_*.py')
→ 対象モジュールに対応するテストファイルを特定
```

### 4.2 テスト実行とカバレッジ計測

```bash
Bash('uv run pytest [対象テスト] --cov=[対象モジュール] --cov-report=term-missing')
```

### 4.3 テスト品質の確認

| 種類 | 確認内容 |
|------|----------|
| 正常系 | 主要機能の動作確認 |
| 異常系 | 例外発生時の動作 |
| エッジケース | 境界値、空値、異常値 |

---

## ステップ5: セキュリティ検証

`Skill('validation')`の**セキュリティモード**を使用。

### 5.1 機密情報の検出

```
Grep('password|secret|api_key|token', '[対象パス]', ignore_case=True)
Grep('AKIA|sk-|ghp_', '[対象パス]')  # AWS/OpenAI/GitHub keys
```

### 5.2 危険なパターンの検出

```
# SQLインジェクション
Grep('execute\(.*%s|execute\(.*\.format', '[対象パス]')

# コマンドインジェクション
Grep('os\.system|subprocess\.call.*shell=True', '[対象パス]')

# 安全でないデシリアライズ
Grep('pickle\.load|yaml\.load\(', '[対象パス]')

# eval/execの使用
Grep('eval\(|exec\(', '[対象パス]')
```

### 5.3 入力検証の確認

- ユーザー入力のサニタイズ
- ファイルパスのバリデーション
- URL/外部入力の検証

---

## ステップ6: パフォーマンス検証

`Skill('validation')`の**パフォーマンスモード**を使用。

### 6.1 非効率なパターンの検出

```
# N+1クエリパターン
Grep('for.*in.*:.*\n.*fetch|for.*in.*:.*\n.*query', '[対象パス]')

# 同期的なI/O（async推奨の場合）
Grep('requests\.get|requests\.post', '[対象パス]')
```

### 6.2 リソース使用の確認

```
# 大きなデータのメモリ展開
Grep('\.read\(\)|list\(.*generator', '[対象パス]')

# ファイルハンドルのリーク
Grep('open\(', '[対象パス]')  # withの使用確認
```

### 6.3 async/await の適切な使用

```
# 同期関数内でのasync呼び出し
Grep('asyncio\.run\(', '[対象パス]')
```

---

## ステップ7: 検証レポートの生成

`Skill('validation')`の**レポート生成モード**を使用。

### 出力形式

```markdown
# コード検証レポート

> 生成日時: {YYYY-MM-DD HH:MM}
> 対象: {パス / steeringディレクトリ}

## エグゼクティブサマリー

| 検証項目 | 結果 | 詳細 |
|----------|------|------|
| スペック整合性 | {PASS/FAIL} | {充足率}% |
| コード品質 | {PASS/FAIL} | {問題数}件 |
| テストカバレッジ | {PASS/FAIL} | {カバレッジ率}% |
| セキュリティ | {PASS/FAIL} | 高{N}/中{N}件 |
| パフォーマンス | {PASS/FAIL} | {問題数}件 |
| **総合判定** | **{PASS/FAIL/CONDITIONAL_PASS}** | |

## 1. スペックとの整合性

### 要件トレーサビリティ
| 要件ID | 条件 | 結果 | 根拠 |
|--------|------|------|------|
| REQ-01 | {条件} | {PASS/FAIL} | {ファイル:行} |

### 設計との整合性
| 設計項目 | 期待 | 実装 | 結果 |
|----------|------|------|------|
| {クラス名} | {仕様} | {状況} | {PASS/FAIL} |

## 2. コード品質

### ruff check
{問題リスト}

### mypy
{型エラーリスト}

### ベストプラクティス
| 項目 | 状態 | コメント |
|------|------|----------|
| エラーハンドリング | OK/NG | {詳細} |
| ログ出力 | OK/NG | {詳細} |
| 単一責任 | OK/NG | {詳細} |
| DRY原則 | OK/NG | {詳細} |

## 3. テストカバレッジ

### カバレッジサマリー
| モジュール | 行数 | カバー | 率 |
|------------|------|--------|-----|
| {module} | {total} | {covered} | {rate}% |

### テスト品質
| 種類 | 件数 | 状態 |
|------|------|------|
| 正常系 | {N} | OK/不足 |
| 異常系 | {N} | OK/不足 |
| エッジケース | {N} | OK/不足 |

## 4. セキュリティ

### 検出された問題
| 重大度 | カテゴリ | ファイル | 行 | 内容 |
|--------|----------|----------|-----|------|
| {高/中} | {category} | {path} | {line} | {description} |

### セキュリティチェックリスト
| 項目 | 状態 |
|------|------|
| 機密情報のハードコード | OK/NG |
| インジェクション対策 | OK/NG/N/A |
| 入力バリデーション | OK/NG |

## 5. パフォーマンス

### 検出された問題
| 影響度 | カテゴリ | ファイル | 行 | 内容 |
|--------|----------|----------|-----|------|
| {高/中} | {category} | {path} | {line} | {description} |

### パフォーマンスチェックリスト
| 項目 | 状態 | コメント |
|------|------|----------|
| 非同期I/O活用 | OK/NG | {詳細} |
| メモリ効率 | OK/NG | {詳細} |
| N+1問題 | OK/NG | {詳細} |
| リソース解放 | OK/NG | {詳細} |

## 6. 推奨事項

### 優先度: 高（修正必須）
- {問題}: {推奨対応}

### 優先度: 中（修正推奨）
- {問題}: {推奨対応}

### 優先度: 低（検討事項）
- {問題}: {推奨対応}

## 7. 次のアクション

- [ ] {アクション1}
- [ ] {アクション2}
```

---

## ステップ8: レポートの保存

検証レポートをsteeringディレクトリに保存します。

```
Write('[steeringパス]/validation-report.md', レポート内容)
```

**保存先:**
- steeringディレクトリ指定時: `[steeringパス]/validation-report.md`
- パス指定時: レポートは画面出力のみ（保存しない）

**上書き動作:**
- 既存のレポートがある場合は上書きする（最新の検証結果のみ保持）

---

## 判定基準

### 各項目の合否

| 項目 | PASS条件 | CONDITIONAL_PASS条件 |
|------|----------|----------------------|
| スペック整合性 | 100%充足 | 90%以上充足 |
| コード品質 | エラー0件 | 軽微な警告10件以下 |
| テストカバレッジ | 80%以上 | 60%以上 |
| セキュリティ | 高0件、中0件 | 高0件、中3件以下 |
| パフォーマンス | 高0件 | 高0件、中3件以下 |

### 総合判定

| 条件 | 判定 |
|------|------|
| 全項目PASS | **PASS** |
| 高優先度の問題が1件以上 | **FAIL** |
| CONDITIONAL_PASSが1項目以上 | **CONDITIONAL_PASS** |

### FAIL時の対応

1. 問題箇所を特定
2. 修正コードを提案
3. `/validate-code`を再実行して確認

---

## 注意事項

- 検証は破壊的な変更を行いません（読み取りのみ）
- 大規模なコードベースでは対象を絞って実行することを推奨
- テストが存在しない場合は「テストカバレッジ」はスキップ可能
